{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOLbo5zqhDq18taMwQQeAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alvise84/Computer_Vision/blob/main/Digit_Reconstruction_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Digit Reconstruction VAE**"
      ],
      "metadata": {
        "id": "S0Q5TN9uE5di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Описание проекта**\n",
        "\n",
        "Цель данного проекта — создание вариационного автокодировщика (VAE) для реконструкции цифр из датасета MNIST. Модель будет обучаться на бинаризованных изображениях цифр и способна будет восстанавливать исходные изображения из латентного представления. Кроме того, модель позволит исследовать латентное пространство и генерировать новые цифры."
      ],
      "metadata": {
        "id": "pRAtEM-aFDck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Примеры применения**\n",
        "\n",
        "**Обработка изображений:** Модель может быть использована для очистки и восстановления поврежденных изображений цифр.\n",
        "\n",
        "**Генерация данных:** Для создания синтетических данных, которые могут быть использованы в задачах обучения машин и улучшении моделей.\n",
        "\n",
        "**Исследование латентного пространства:** Анализ структуры латентного пространства может помочь понять, как модель представляет различные цифры.\n",
        "\n",
        "**Компрессия данных:** Модель может использоваться для сжатия и хранения изображений цифр в компактной форме.\n",
        "\n",
        "**Обнаружение аномалий:** Использование VAE для выявления аномалий в наборе данных, например, искаженных или неправильно классифицированных изображений.\n"
      ],
      "metadata": {
        "id": "6M3ZmwW0FbN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 1: **Установка необходимых библиотек**\n",
        "\n",
        "Устанавливаем необходимые библиотеки для работы с данными, обучением модели и визуализацией результатов. Эти библиотеки предоставляют инструменты для работы с тензорами, загрузки и предобработки данных, обучения моделей и построения графиков. Используем torch и torchvision для работы с нейронными сетями, matplotlib — для визуализации, а numpy — для работы с массивами данных."
      ],
      "metadata": {
        "id": "Dhpa_7cuGFdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib numpy"
      ],
      "metadata": {
        "id": "WUDJ0TNWGLk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 2: **Импорт библиотек**\n",
        "\n",
        "Импортируем необходимые модули и классы из установленных библиотек. Эти модули и классы используются для создания и обучения модели, работы с данными и визуализации результатов. Используем стандартные импорты для удобства и совместимости с другими частями кода."
      ],
      "metadata": {
        "id": "_2f1zBY7GRsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azy5y4oREvV9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions import Independent, Normal, Bernoulli\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torchvision.datasets import MNIST\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 3: **Установка фиксированного seed для воспроизводимости**\n",
        "\n",
        "Устанавливаем фиксированный seed для всех случайных процессов. Это обеспечивает воспроизводимость результатов экспериментов, что важно для сравнения различных моделей и настроек. Используем torch.manual_seed для CPU и torch.cuda.manual_seed_all для GPU, а также настраиваем параметры cudnn для детерминированного режима."
      ],
      "metadata": {
        "id": "P19aif66GcNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "p0b1DBkbGfAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 4: **Определение пользовательского класса Dataset**\n",
        "\n",
        "Создаем пользовательский класс для загрузки данных из сохраненных файлов. Этот класс позволяет работать с данными, сохраненными в формате .pt, и применять к ним трансформации. Наследуемся от torch.utils.data.Dataset для удобства использования с DataLoader."
      ],
      "metadata": {
        "id": "XzQBqMdAGqJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransposedMNISTDataset(Dataset):\n",
        "    def __init__(self, file_path: str, transform=None):\n",
        "        self.data = torch.load(file_path, weights_only=False)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "kA2CEffmGr_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 5: **Определение трансформаций для данных**\n",
        "\n",
        "Определяем последовательность трансформаций для предобработки изображений. Трансформации нужны для нормализации изображений и их преобразования в бинарные значения. Используем ToTensor для преобразования изображений в тензоры, view для преобразования в одномерный вектор и Lambda для бинаризации."
      ],
      "metadata": {
        "id": "24v7wxEKG54w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "    transforms.Lambda(lambda x: (x > 0.5).float()),\n",
        "])"
      ],
      "metadata": {
        "id": "4MD-j_TaG7-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 6: **Проверка наличия файлов и пересохранение данных**\n",
        "\n",
        "Проверяем наличие файлов с данными и пересохраняем их, если они отсутствуют или некорректны. Это гарантирует, что данные всегда будут загружены и сохранены в нужном формате. Используем os.path.exists для проверки наличия файлов и torch.save для сохранения данных."
      ],
      "metadata": {
        "id": "WYzgMIjEHEBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = 'transposed_mnist_train.pt'\n",
        "test_file_path = 'transposed_mnist_test.pt'\n",
        "\n",
        "if os.path.exists(train_file_path):\n",
        "    os.remove(train_file_path)\n",
        "if os.path.exists(test_file_path):\n",
        "    os.remove(test_file_path)\n",
        "\n",
        "print(\"Файлы не найдены или имеют некорректную форму. Пересохраняем данные...\")\n",
        "\n",
        "original_train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "original_test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_data = [(img, label) for img, label in original_train_dataset]\n",
        "test_data = [(img, label) for img, label in original_test_dataset]\n",
        "\n",
        "torch.save(train_data, 'transposed_mnist_train.pt')\n",
        "torch.save(test_data, 'transposed_mnist_test.pt')\n",
        "\n",
        "print(\"Данные успешно пересохранены.\")"
      ],
      "metadata": {
        "id": "hlOps34FHGWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 7: **Проверка наличия файлов и создание экземпляров Dataset**\n",
        "\n",
        "Проверяем наличие файлов с данными и создаем экземпляры пользовательского класса Dataset. Это позволяет использовать данные для обучения и тестирования модели. Используем os.path.exists для проверки наличия файлов и создаем экземпляры TransposedMNISTDataset для работы с данными."
      ],
      "metadata": {
        "id": "HUcaPn8hLA80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(train_file_path):\n",
        "    print(f\"Файл {train_file_path} не найден.\")\n",
        "else:\n",
        "    print(f\"Файл {train_file_path} найден.\")\n",
        "    train_dataset = TransposedMNISTDataset(file_path=train_file_path, transform=None)\n",
        "    print(f\"Количество образцов в обучающем наборе: {len(train_dataset)}\")\n",
        "\n",
        "if not os.path.exists(test_file_path):\n",
        "    print(f\"Файл {test_file_path} не найден.\")\n",
        "else:\n",
        "    print(f\"Файл {test_file_path} найден.\")\n",
        "    test_dataset = TransposedMNISTDataset(file_path=test_file_path, transform=None)\n",
        "    print(f\"Количество образцов в тестовом наборе: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "31ibDz0iLI4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 8: **Проверка содержимого файлов**\n",
        "\n",
        "Проверяем типы и размеры данных в загруженных файлах. Это помогает убедиться, что данные загружены правильно и имеют ожидаемую структуру. Используем torch.load для загрузки данных и выводим информацию о типах и размерах."
      ],
      "metadata": {
        "id": "LIqluIFdLSKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(train_file_path):\n",
        "    train_data = torch.load(train_file_path, weights_only=False)\n",
        "    print(f\"Тип данных в train_data: {type(train_data)}\")\n",
        "    print(f\"Тип первого образца: {type(train_data[0][0])}\")\n",
        "    print(f\"Размер первого образца: {train_data[0][0].size()}\")\n",
        "    print(f\"Тип первой метки: {type(train_data[0][1])}\")\n",
        "    print(f\"Значение первой метки: {train_data[0][1]}\")\n",
        "\n",
        "if os.path.exists(test_file_path):\n",
        "    test_data = torch.load(test_file_path, weights_only=False)\n",
        "    print(f\"Тип данных в test_data: {type(test_data)}\")\n",
        "    print(f\"Тип первого образца: {type(test_data[0][0])}\")\n",
        "    print(f\"Размер первого образца: {test_data[0][0].size()}\")\n",
        "    print(f\"Тип первой метки: {type(test_data[0][1])}\")\n",
        "    print(f\"Значение первой метки: {test_data[0][1]}\")"
      ],
      "metadata": {
        "id": "h8kFxh67LYnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 9: **Определение параметров модели**\n",
        "\n",
        "Определяем параметры модели, такие как размер латентного пространства, скрытого слоя и размер входного изображения. Эти параметры влияют на архитектуру модели и её способность к обучению. Выбираем значения, которые обеспечивают баланс между сложностью модели и вычислительными ресурсами."
      ],
      "metadata": {
        "id": "BnFBymeoLjDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d, nh, D = 32, 200, 28 * 28  # Размер латентного пространства, скрытого слоя, размер входного изображения"
      ],
      "metadata": {
        "id": "0cgpNXq5LsuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 10: **Определение устройства (GPU или CPU)**\n",
        "\n",
        "Определяем устройство для выполнения вычислений (GPU или CPU). Это позволяет использовать доступные вычислительные ресурсы для ускорения обучения модели. Используем torch.device для автоматического выбора устройства."
      ],
      "metadata": {
        "id": "iFSm4uQ-L0z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "GnjG_ddIL20c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 11: **Определение энкодера и декодера**\n",
        "\n",
        "Определяем архитектуру энкодера и декодера. Эти компоненты модели необходимы для кодирования входных данных в латентное пространство и декодирования обратно в исходное пространство. Используем последовательные слои Linear и ReLU для создания нейронных сетей, а Sigmoid для нормализации выхода декодера."
      ],
      "metadata": {
        "id": "ygUdH54nMFM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = nn.Sequential(\n",
        "    nn.Linear(D, nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, 2 * d)  # 2 * d для mu и log_var\n",
        ").to(device)\n",
        "\n",
        "dec = nn.Sequential(\n",
        "    nn.Linear(d, nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, D),\n",
        "    nn.Sigmoid()  # Добавляем Sigmoid для нормализации выхода в диапазон [0, 1]\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "CkOLWnE-MNMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 12: **Инициализация весов**\n",
        "\n",
        "Инициализируем веса нейронных сетей. Корректная инициализация весов помогает ускорить обучение и предотвращает проблемы с затуханием или взрывом градиентов. Используем xavier_uniform_ для инициализации весов и constant_ для инициализации смещений."
      ],
      "metadata": {
        "id": "MWgVh9pqMWr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "enc.apply(init_weights)\n",
        "dec.apply(init_weights)"
      ],
      "metadata": {
        "id": "SeSbhkwPMfdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 13: **Определение класса VAE**\n",
        "\n",
        "Определяем класс VAE, который объединяет энкодер и декодер. Этот класс позволяет легко использовать модель для обучения и инференса. Наследуемся от torch.nn.Module и определяем методы для кодирования, декодирования и прямого прохода."
      ],
      "metadata": {
        "id": "wi1CXBRtMoHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, enc, dec):\n",
        "        super(VAE, self).__init__()\n",
        "        self.enc = enc\n",
        "        self.dec = dec\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.enc(x)\n",
        "        mean = h[:, :d]\n",
        "        logvar = h[:, d:]\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        generator = torch.Generator().manual_seed(seed)\n",
        "        eps = torch.randn(std.size(), device=mean.device, generator=generator)\n",
        "        z = mean + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        logits = self.dec(z)\n",
        "        return logits\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        logits = self.decode(z)\n",
        "        return logits, mean, logvar"
      ],
      "metadata": {
        "id": "9mfOQ_BQMxy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 14: **Функция потерь ELBO с использованием Bernoulli распределения**\n",
        "\n",
        "Определяем функцию потерь ELBO для обучения VAE. Функция потерь ELBO используется для минимизации различий между реконструкцией и оригинальным изображением, а также для регуляризации латентного пространства. Используем Independent для работы с многомерными распределениями и kl_divergence для вычисления KL-дивергенции."
      ],
      "metadata": {
        "id": "4RRCFgM5M3DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_vae(x, vae):\n",
        "    batch_size = x.size(0)\n",
        "    recon_probs, mean, logvar = vae(x)\n",
        "\n",
        "    epsilon = 1e-7\n",
        "    recon_probs = torch.clamp(recon_probs, min=epsilon, max=1 - epsilon)\n",
        "\n",
        "    pz = Independent(Normal(loc=torch.zeros(batch_size, d).to(x.device),\n",
        "                            scale=torch.ones(batch_size, d).to(x.device)),\n",
        "                     reinterpreted_batch_ndims=1)\n",
        "    qz_x = Independent(Normal(loc=mean,\n",
        "                              scale=torch.exp(0.5 * logvar)),\n",
        "                       reinterpreted_batch_ndims=1)\n",
        "\n",
        "    px_z = Independent(Bernoulli(probs=recon_probs),\n",
        "                       reinterpreted_batch_ndims=1)\n",
        "\n",
        "    log_px_z = px_z.log_prob(x).sum(dim=-1)\n",
        "    kl_div = torch.distributions.kl_divergence(qz_x, pz).sum(dim=-1)\n",
        "    elbo = log_px_z - kl_div\n",
        "\n",
        "    return -elbo.mean(), recon_probs"
      ],
      "metadata": {
        "id": "p83moDE6NE7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 15: **Функция генерации образцов из латентного пространства**\n",
        "\n",
        "Определяем функцию для генерации новых образцов из латентного пространства. Эта функция позволяет создавать новые изображения цифр, основываясь на случайных точках в латентном пространстве. Используем torch.randn для генерации случайных точек и sigmoid для нормализации выхода."
      ],
      "metadata": {
        "id": "Dgn6mpzeNMyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_vae(dec, n_samples=50):\n",
        "    with torch.no_grad():\n",
        "        samples = torch.sigmoid(dec(torch.randn(n_samples, d).to(device)))\n",
        "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
        "    return samples"
      ],
      "metadata": {
        "id": "7vnuHBMdNTcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 16: **Функция визуализации образцов**\n",
        "\n",
        "Определяем функцию для визуализации сгенерированных образцов. Эта функция позволяет визуально оценить качество генерируемых изображений. Используем matplotlib для создания сетки изображений."
      ],
      "metadata": {
        "id": "fun5nrWgNXkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_samples(samples, h=5, w=10):\n",
        "    fig, axes = plt.subplots(nrows=h,\n",
        "                             ncols=w,\n",
        "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
        "                             subplot_kw={'xticks': [], 'yticks': []})\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(samples[i], cmap='gray')"
      ],
      "metadata": {
        "id": "Ad1OYE3DNgfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 17: **Функция визуализации реконструкций**\n",
        "\n",
        "Определяем функцию для визуализации реконструкций тестовых образцов. Эта функция позволяет оценить качество восстановления изображений моделью. Используем matplotlib для создания сетки изображений оригиналов и реконструкций."
      ],
      "metadata": {
        "id": "I4rKbI5dNm_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstructions(vae, test_loader, n_samples=25):\n",
        "    with torch.no_grad():\n",
        "        data, _ = next(iter(test_loader))\n",
        "        data = data[:n_samples].to(device)\n",
        "        recon_probs, _, _ = vae(data)\n",
        "        recon_probs = torch.sigmoid(recon_probs)\n",
        "        recon_probs = recon_probs.view(n_samples, 28, 28).cpu().numpy()\n",
        "        data = data.view(n_samples, 28, 28).cpu().numpy()\n",
        "\n",
        "        fig, axes = plt.subplots(nrows=n_samples // 5, ncols=10, figsize=(14, 7),\n",
        "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
        "        for i in range(n_samples):\n",
        "            if i % 5 == 0:\n",
        "                axes[i // 5, 2 * (i % 5)].set_title(\"Orig\")\n",
        "                axes[i // 5, 2 * (i % 5) + 1].set_title(\"Recon\")\n",
        "            axes[i // 5, 2 * (i % 5)].imshow(data[i], cmap='gray')\n",
        "            axes[i // 5, 2 * (i % 5) + 1].imshow(recon_probs[i], cmap='gray')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "2CxKxZt_NuLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 18: **Функция обучения модели**\n",
        "\n",
        "Определяем функцию для обучения модели VAE. Эта функция выполняет обучение модели на обучающем наборе данных и оценивает её качество на тестовом наборе данных. Используем torch.optim.Adam для оптимизации параметров модели и DataLoader для загрузки данных в батчах."
      ],
      "metadata": {
        "id": "Vl5UfiBpN1n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(loss_fn, model, train_loader, test_loader, num_epochs, learning_rate=1e-3):\n",
        "    vae = VAE(model[0], model[1]).to(device)\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        vae.train()\n",
        "        total_train_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss, _ = loss_fn(data, vae)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        vae.eval()\n",
        "        total_test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, _) in enumerate(test_loader):\n",
        "                data = data.to(device)\n",
        "                loss, _ = loss_fn(data, vae)\n",
        "                total_test_loss += loss.item()\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_loader)\n",
        "        test_losses.append(avg_test_loss)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Test Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plot_reconstructions(vae, test_loader, n_samples=25)\n",
        "\n",
        "    vae.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
        "        for i, (data, labels) in enumerate(sample_loader):\n",
        "            data = data.to(device)\n",
        "            mean, logvar = vae.encode(data)\n",
        "            break\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.scatter(mean[:, 0].cpu().numpy(), mean[:, 1].cpu().numpy(), c=labels.cpu().numpy(), cmap='tab10')\n",
        "        plt.colorbar(label='Digit Label')\n",
        "        plt.xlabel('Latent Dimension 1')\n",
        "        plt.ylabel('Latent Dimension 2')\n",
        "        plt.title('Latent Space Visualization')\n",
        "        plt.show()\n",
        "\n",
        "    vae.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(50, d, device=device)\n",
        "        generated_images = vae.decode(z)\n",
        "\n",
        "        samples = generated_images.view(50, 28, 28).cpu().numpy()\n",
        "        plot_samples(samples, h=5, w=10)"
      ],
      "metadata": {
        "id": "fwucnUETN9Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 19: **Использование DataLoader**\n",
        "\n",
        "Создаем экземпляры DataLoader для загрузки данных в батчах. Это позволяет эффективно загружать и перемешивать данные для обучения и тестирования. Используем DataLoader с указанием размера батча и режима перемешивания."
      ],
      "metadata": {
        "id": "mXStHyacOHY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "2tncPvlWOOlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 20: **Создание экземпляра VAE**\n",
        "\n",
        "Создаем экземпляр модели VAE, объединяя энкодер и декодер. Это позволяет легко передавать модель в функции для обучения и инференса. Создаем список с энкодером и декодером для удобства передачи в функции."
      ],
      "metadata": {
        "id": "6micUG--OSRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = [enc, dec]"
      ],
      "metadata": {
        "id": "66pirgyvOagr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 21: **Обучение модели**\n",
        "\n",
        "Обучаем модель VAE на заданном количестве эпох. Это позволяет моделью научиться реконструировать изображения и генерировать новые цифры. Используем функцию train_model с заданными параметрами для обучения модели."
      ],
      "metadata": {
        "id": "U5pg6zbROhhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(loss_vae, model=model, train_loader=train_loader, test_loader=test_loader, num_epochs=10)"
      ],
      "metadata": {
        "id": "t8NbRJfxOnPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Заключение**\n",
        "\n",
        "В данном проекте мы создали и обучили вариационный автокодировщик для реконструкции цифр из датасета MNIST. Модель показала хорошие результаты в восстановлении изображений и демонстрирует потенциал для дальнейшего исследования латентного пространства и генерации новых изображений."
      ],
      "metadata": {
        "id": "Je03VM4XOveo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jZwjULeOyTb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}